Minor Revisions

The revised draft is a significant improvement and addresses the core issues comprehensively. The proposed method is novel, and the experimental plan is rigorous, falsification-oriented, and well-aligned with the paper's claims. The focus on efficiency (gating, hierarchical scoring) and robustness (specificity prior, structural checks) is commendable.

The following minor revisions aim to further improve clarity and structural flow:
- **Structure:** The "Efficiency and Engineering" section is methodologically crucial and would be better integrated as a subsection within "Method" to create a more unified narrative.
- **Clarity:** The introduction's "Limitations of prior art" can be reframed from a list to a paragraph for better readability. The pseudocode can be clarified to make the mapping from candidates to rollouts and scores more explicit.
- **Precision:** The `logit` function for the consistency bonus is a strong choice but its properties are worth stating explicitly for reproducibility.

The draft is exceptionally strong; these are refinements, not fundamental corrections.

Revised Draft
# Lookahead-Consistency Decoding: Risk-Aware Token Selection via Semantic Agreement of Micro-Rollouts

## Abstract
We propose Lookahead-Consistency Decoding (LCD), a decoding-time algorithm that reduces unforced errors by preferring tokens whose short-term futures exhibit high semantic agreement. For each high-potential next token, LCD uses a small draft model to generate brief "micro-rollouts." It then scores the semantic consistency of these futures using a lightweight hierarchy: efficient embedding-based consensus followed by selective, high-precision NLI checks. The resulting consistency score modulates the target model’s logits, penalizing locally divergent or unstable choices. Unlike speculative decoding (which targets speed) or verifier reranking (which operates at the sequence level), LCD provides a token-local, preventive signal against semantic instability. We detail an efficiency-focused design with uncertainty gating and batched KV reuse and propose a rigorous experimental plan on factuality, structured generation, and agentic tasks using small open models.

## 1. Introduction
Standard autoregressive decoding methods like top-p sampling commit to locally probable tokens without regard for their downstream consequences. This greedy approach can lead the model into semantically unstable states, resulting in factual hallucinations, logical contradictions, or brittle structured outputs.

Existing methods to improve reliability operate at the wrong granularity. Self-consistency and verifier-based reranking are post hoc, requiring multiple full-length generations and incurring substantial computational costs. Contrastive methods like DoLa adjust logits based on internal model states but do not explicitly probe multi-token consequences. Consistency-based estimators like SelfCheckGPT assess output-level contradictions, also a post hoc signal. Finally, speculative decoding accelerates inference but does not improve output quality. What is missing is a lightweight, preventive mechanism that assesses the semantic risk of a token *before* it is selected.

We introduce Lookahead-Consistency Decoding (LCD), which estimates local semantic stability by probing candidate tokens with cheap micro-rollouts. It favors tokens whose futures agree semantically, providing a real-time risk signal to guide the decoding process.

**Contributions:**
1.  **LCD:** A token-level lookahead algorithm that modulates logits based on the semantic agreement of short-term futures generated by a draft model.
2.  **Efficient Implementation:** A practical design incorporating uncertainty gating, a hierarchical scoring cascade (embedding pre-filter → selective NLI), and batched, KV-cached rollouts to minimize overhead.
3.  **Rigorous Falsification Plan:** A compute-normalized evaluation protocol across factuality (TruthfulQA) and structured-output tasks (WikiSQL, function-calling) with strong baselines and comprehensive ablations.
4.  **Open Validation:** An end-to-end implementation and validation using small, open-source models (Pythia-1.4B, TinyLlama-1.1B, DeBERTa-MNLI) to ensure reproducibility.

## 2. Method

### 2.1 Overview and Notation
- **Target Model (T):** The primary model being guided (e.g., Pythia-1.4B).
- **Draft Model (D):** A smaller, faster model for generating rollouts (e.g., TinyLlama-1.1B).
- **Scorers:** An embedding encoder **E** (e.g., `all-MiniLM-L6-v2`) and an optional NLI model **S** (e.g., `deberta-v3-small-mnli`).
- At step *t* with context *C*, T produces a next-token distribution *P<sub>T</sub>*. We select *m* candidate tokens from this distribution.

### 2.2 Uncertainty-Gated Activation
To manage computational cost, LCD is activated only at "risky" steps, defined by conditions like:
- High entropy: H(*P<sub>T</sub>*) ≥ *h*.
- Low top-token margin: *p<sub>1</sub>* − *p<sub>2</sub>* ≤ *δ*.
- Representation drift: Cosine distance between current and previous hidden states ≥ *ρ*.
Otherwise, we default to standard sampling. The gate is tuned to activate on 20–30% of generation steps.

### 2.3 Candidate Selection and Micro-Rollouts
- **Candidates (A):** A set of *m* tokens is sampled from *P<sub>T</sub>* using top-p/top-k with temperature *τ<sub>T</sub>*.
- **Rollouts:** For each candidate *a* ∈ *A*, we generate *k* short continuations (rollouts) of length *L* using the draft model *D*. This process uses a moderate temperature *τ<sub>D</sub>* to ensure plausible but diverse futures.
- **Efficiency:** The KV cache for the context *C* is shared across all *m* × *k* rollouts.

### 2.4 Hierarchical Agreement Scoring
We use a two-stage process to score agreement efficiently and robustly.

**Step 1: Embedding Consensus (Cheap Filter)**
- For each candidate *a*, its *k* rollouts are encoded with **E**.
- Pairwise cosine similarity is computed among the *k* embedding vectors. The mean similarity is the preliminary score, *s<sub>emb</sub>*.
- A **specificity prior** is added to penalize generic, low-information rollouts (e.g., "I'm not sure..."). The score `spec` is calculated from the sum of IDF-weighted token frequencies in the rollout, normalized by length.
- The initial score is: *s<sub>0</sub>* = *s<sub>emb</sub>* − *λ*(1 − `spec`), where *λ* is a hyperparameter.

**Step 2: Selective NLI (Expensive Refinement)**
- The top *u* candidates (e.g., *u* ≤ 2) ranked by *s<sub>0</sub>* are selected for NLI-based scoring.
- For each of these candidates, we compute pairwise NLI scores across its *k* rollouts. The NLI score, *s<sub>nli</sub>*, is the mean entailment probability minus the mean contradiction probability.
- The final agreement score *s* is a weighted average: *s* = α·*s<sub>0</sub>* + (1−α)·*s<sub>nli</sub>*. Candidates not evaluated with NLI retain their *s<sub>0</sub>* score.

**Specialization for Structured Outputs:** For tasks like SQL or code generation, NLI is replaced with structural checks (e.g., parse validity, AST edit distance). The score *s<sub>struct</sub>* reflects structural similarity, and the final score becomes *s* = α·*s<sub>0</sub>* + (1−α)·*s<sub>struct</sub>*.

### 2.5 Logit Modulation
- The agreement score *s(a)* for each candidate *a* is used to adjust T's original logits *z(a)*.
- **Consistency Bonus:** We compute a bonus *b(a)* = *β* · log(*s(a)* / (1−*s(a)*)), which is the logit function scaled by a task-tuned hyperparameter *β*. The score *s(a)* is clipped to [ε, 1−ε] to ensure stability.
- **Adjusted Logits:** *z'(a)* = *z(a)* + *b(a)* for *a* ∈ *A*.
- **Final Selection:** An optional hard filter may discard candidates where *s(a)* < *τ*. The next token is sampled from softmax(*z'*) using the original temperature.

### 2.6 Implementation and Compute
- **Batching:** All *m* × *k* rollouts are generated in a single batch, reusing the KV cache for the shared context *C*. NLI and embedding computations are also batched.
- **Cost Model:** The per-step overhead is approximately *m*·*k*·*L* draft tokens plus the cost of *m*·*k* embedding encodings and *u*·*k*(*k*−1)/2 NLI inferences. We will report both FLOPs and wall-clock latency.
- **Typical Settings:** *m*=4, *k*=2, *L*=6, *u*=2, gating rate ≈ 25%. Target overhead is <2x median latency on an A100 for a 1.4B parameter target model.

### 2.7 Pseudocode (Single Step)
```python
def lcd_step(C, T, D, E, S, params):
    if not is_risky_step(T, C, params):
        return sample_from_T(T, C, params)

    A, logits = get_candidate_set(T, C, params.m)
    # rollouts is a dict: {token_id: [rollout_str_1, ...]}
    rollouts = sample_rollouts(D, C, A, params.k, params.L, batch=True)

    scores = {}
    for a in A:
        s_emb = embedding_consensus(rollouts[a], E)
        spec = specificity_score(rollouts[a])
        scores[a] = s_emb - params.lambda * (1 - spec)

    # Refine top u candidates with NLI
    A_sel = top_u_by_score(A, scores, params.u)
    for a in A_sel:
        s_nli = nli_consensus(rollouts[a], S, batch=True)
        scores[a] = params.alpha * scores[a] + (1 - params.alpha) * s_nli

    # Modulate logits and sample
    z_prime = logits.clone()
    for a in A:
        sa = clip(scores[a], params.eps, 1 - params.eps)
        if sa >= params.tau:
            z_prime[a] += params.beta * logit(sa) # logit(p)=log(p/(1-p))

    return sample_from_logits(z_prime)
```

## 3. Experimental Validation

### 3.1 Hypotheses and Falsification
- **H1 (Quality):** LCD improves primary metrics by ≥3% absolute over tuned baselines at matched or lower end-to-end compute.
- **H2 (Efficiency):** With gating and hierarchical scoring, the median latency overhead is ≤2.0x that of standard decoding.
- **H3 (Mechanism):** The average agreement score *s(a)* of chosen tokens is positively correlated with final output correctness, and quality improvements are concentrated at gated ("risky") steps.

**Falsification Criteria:** We will reject our claims if (1) LCD shows no statistically significant improvement on primary metrics vs. compute-matched baselines, (2) latency overhead exceeds 2.5x without dramatic quality gains, or (3) the agreement score shows no correlation with correctness.

### 3.2 Tasks and Metrics
- **TruthfulQA (Generation):** %True, %Truthful+Informative.
- **BioASQ (Factoid QA):** Exact Match (EM) and F1.
- **WikiSQL:** Exact Match and Execution Accuracy.
- **Function-Calling Accuracy:** Exact tool and argument match on a ToolBench-style subset.

### 3.3 Models
- **T:** Pythia-1.4B, Mistral-7B-Instruct.
- **D:** TinyLlama-1.1B, Pythia-410M.
- **E:** `all-MiniLM-L6-v2`.
- **S:** `deberta-v3-small-mnli`, `deberta-v3-base-mnli`.

### 3.4 Baselines
- Standard decoding: Greedy, tuned top-p sampling, beam search (width=4).
- **Self-Consistency:** Best of *k*=5 full generations with majority vote.
- **Verifier-Reranked Beam Search:** Reranking beams using an NLI or task-specific verifier, compute-matched to LCD.
- **Best-of-N:** Generating *N* full outputs and reranking with a verifier, with the total draft/verifier budget matched to LCD's per-output budget.
- **SelfCheckGPT-style Scoring:** Post hoc contradiction scoring on full outputs.
- **Contrastive Decoding:** An open implementation of DoLa/CD.

### 3.5 Protocol
- **Compute-Normalization:** All baselines are allocated a total FLOP/latency budget equal to that of LCD.
- **Significance:** We will report mean±95% CI over 1k bootstrap replicates.
- **Controls:** All evaluations are length-controlled. We test robustness across ≥5 random seeds and perform a temperature sweep for all methods.
- **Ablations:** We will test versions of LCD without gating, with embedding-only or NLI-only scoring, without the specificity prior, and with weaker draft models to probe failure modes.

## 4. Relation to Prior Work
LCD synthesizes ideas from several domains but is distinct in its approach. Unlike **self-consistency** or **verifier-reranking**, which are solution-level, post hoc methods, LCD provides a token-local, preventive signal. Unlike **speculative decoding**, its goal is quality, not speed, though it is composable with speculative acceptance. While **SelfCheckGPT** also uses consistency, it operates post hoc on full outputs to detect hallucinations, whereas LCD injects an agreement prior during decoding to prevent them. Finally, unlike internal **contrastive methods** (e.g., DoLa), LCD explicitly probes external, multi-token futures.

## 5. Limitations
- **Overhead:** The method's practicality depends heavily on efficient gating and batching.
- **Scorer Fragility:** NLI on short text can be unreliable; this is mitigated by the embedding pre-filter, specificity prior, and domain-specific structural checks.
- **Degeneration Risk:** Penalizing divergence can suppress creative or minority-correct answers. This is mitigated by the specificity prior and by scoping LCD to reliability-critical domains like function calling and factual recall.
- **Myopia:** Short rollouts (*L*) may fail to detect long-range contradictions.

## 6. Conclusion
Lookahead-Consistency Decoding introduces a token-local, preventive stability prior into autoregressive generation. By scoring the semantic agreement of cheap micro-rollouts, it aims to guide language models away from unstable trajectories that lead to errors. Our falsification-oriented experimental plan will rigorously test whether this lookahead signal provides meaningful improvements in factuality and structured accuracy at an acceptable computational cost. If validated, LCD offers a composable tool for building more reliable inference systems, particularly for agentic workflows where single-token errors are costly.

## 7. Reproducibility
We will release open-source code with deterministic seeds, Hugging Face model identifiers, and scripts for replicating our batching and KV caching logic. All hyperparameters, evaluation prompts, and analysis notebooks will be made available.

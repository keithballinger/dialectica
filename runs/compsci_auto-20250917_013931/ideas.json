{"ideas":[{"index":1,"title":"Domain-Specific Tokenization Law","summary":"A tokenizer learned from the target domain reduces the minimal parameter count needed to hit a fixed accuracy by ≥30% versus a general tokenizer, holding architecture and data constant.","layperson":"If you learn how to split text into pieces using only data from your problem area, a small model can do the same job with fewer parts. This means smarter word-splitting tailored to your field lets you shrink the model without losing accuracy.","falsification":"Train two identical small models on the same domain dataset: one with a domain-trained tokenizer and one with a generic tokenizer. Sweep model sizes to find the smallest reaching a target accuracy/F1/EM; if the domain tokenizer does not reduce required parameters by ≥30% across ≥3 domains, the theory is false.","ibm_cost_plan":"NA.","novelty":"Posits a quantitative threshold (≥30% parameter reduction) linking domain tokenization to minimal effective model size."},{"index":2,"title":"Entropy–Capacity Matching Principle","summary":"The minimal model capacity needed for a target error scales with the domain’s compressibility (lower entropy means smaller models suffice), predictably across domains.","layperson":"Tasks with more regular, repetitive patterns can be solved by smaller models. The more predictable the data, the less model you need to reach the same accuracy.","falsification":"Estimate empirical entropy/compressibility of multiple domain datasets (e.g., via LZ or N-gram entropy). Train size-swept small models and fit capacity vs. entropy to a monotonic relation with high R²; failure to observe consistent scaling across ≥4 domains falsifies the claim.","ibm_cost_plan":"NA.","novelty":"Introduces a cross-domain predictive law tying measurable data entropy to required small-model capacity."},{"index":3,"title":"Structure-Respecting Inductive Bias Advantage","summary":"Embedding known domain structure (graphs, trees, grammars) in small models yields ≥10% relative accuracy gain and better OOD robustness than unstructured baselines of equal size.","layperson":"If your problem has a known shape—like a network, a tree, or code grammar—building that shape into the model lets a small model work better and handle surprises more reliably.","falsification":"Pick domains with clear structure (e.g., ASTs for code, molecule graphs). Train matched-parameter models: structure-aware vs. generic (MLP/Transformer). Measure in-domain accuracy and OOD shift performance; absence of ≥10% relative gain and superior OOD metrics invalidates the theory.","ibm_cost_plan":"NA.","novelty":"Sets a concrete, testable margin for the benefit of domain-encoded architecture at small scales."},{"index":4,"title":"Latency-Optimal Specialization Threshold","summary":"Under a strict P99 latency budget, a domain-specialized small model achieves higher accuracy than any generalist model meeting the same latency once the budget falls below a measurable threshold.","layperson":"When you must answer really fast, a tailored small model can beat bigger, general-purpose models that also respond fast. There’s a speed limit below which specialization wins.","falsification":"Deploy models behind the same serving stack with enforced P99 latency budgets; sweep budgets and compare best-achievable accuracy among specialized small models vs. generalists. If no crossover point exists where specialized models win at tight budgets, the theory is false.","ibm_cost_plan":"NA.","novelty":"Proposes an empirical latency threshold where specialization strictly dominates accuracy among latency-feasible models."},{"index":5,"title":"Retrieval-Replaces-Parameters Hypothesis","summary":"Adding a lightweight domain retriever to a small model matches the accuracy of a ≥5× larger standalone model while halving learned parameters on knowledge-heavy tasks.","layperson":"Let the model look things up from a domain-specific index instead of memorizing everything. Then a much smaller model can perform as well as a much bigger one.","falsification":"On domain QA/code search tasks, compare (a) small model + retriever vs. (b) larger model without retrieval under equal compute per query; if (a) fails to match accuracy of a ≥5× larger (b) with ≥50% fewer learned parameters, the claim is false.","ibm_cost_plan":"NA.","novelty":"Quantifies a parameter-for-retrieval substitution rate with clear accuracy and parameter thresholds."},{"index":6,"title":"Compositional Decomposition Superlinearity","summary":"Splitting a domain task into K executable subtasks solved by tiny specialists yields accuracy gains exceeding those from allocating the same total parameters to a monolithic model.","layperson":"Breaking a complex job into small, focused steps handled by tiny models beats one bigger model using the same total size. Specializing each step pays off more than just growing one model.","falsification":"Build pipelines for compositional tasks (e.g., codegen: plan→retrieve→synthesize→test) with multiple small experts; compare to a single model with matched total parameters and compute. If the pipeline doesn’t outperform across metrics, the theory is false.","ibm_cost_plan":"NA.","novelty":"Claims superlinear returns from specialist decomposition at fixed total parameter budgets."},{"index":7,"title":"Quantization Robustness in Low-Variety Domains","summary":"Small domain models trained with quantization-aware training retain ≤1% absolute accuracy loss at 4-bit weights/activations when the domain’s token/feature variety is low.","layperson":"In domains with limited vocabulary or feature types, you can compress small models to 4-bit numbers with almost no accuracy drop if you train them for it.","falsification":"Select low-variety domains (e.g., restricted code styles, fixed-format logs) and matched higher-variety controls; train QAT 4-bit vs. 16/32-bit baselines. If loss exceeds 1% in low-variety domains or doesn’t differ from controls, the theory is false.","ibm_cost_plan":"NA.","novelty":"Links domain variety to a precise, testable bound on extreme quantization loss for small models."},{"index":8,"title":"Domain-Curriculum Sample Efficiency Law","summary":"Ordering training by domain-specific difficulty yields a power-law reduction in data needed to reach a target accuracy for small models, with a consistent exponent across tasks in the same domain family.","layperson":"Teaching small models easy-to-hard examples tailored to the domain lets them learn faster, needing fewer examples. The rate of savings follows a predictable curve for related tasks.","falsification":"Construct domain curricula using difficulty signals (e.g., program length, graph diameter) and compare to random ordering over multiple tasks. Fit data-to-accuracy curves; absence of a consistent power-law exponent within a domain family falsifies the claim.","ibm_cost_plan":"NA.","novelty":"Predicts a stable, domain-specific power-law exponent for curriculum-driven data savings in small models."},{"index":9,"title":"Minimal Test-Time Adaptation Sufficiency","summary":"Simple, parameter-light adaptation (e.g., norm-stat updates or feature-wise affine recalibration) recovers ≥50% of accuracy lost under mild covariate shift for small domain models.","layperson":"When the input style changes a bit, tiny on-the-fly tweaks without retraining can bring back at least half of the lost accuracy for small specialized models.","falsification":"Induce controlled covariate shifts (style, noise, sensor bias) and measure baseline drop. Apply only light adaptation (e.g., BN stats, AdaBN, small FiLM layers). If recovery is <50% across multiple shifts/domains, the theory is false.","ibm_cost_plan":"NA.","novelty":"Sets a quantitative recovery floor for extremely cheap test-time adaptation in small domain models."},{"index":10,"title":"Verifier-Adds-More-Than-Parameters Principle","summary":"Attaching a tiny domain-specific verifier/critic to filter or revise outputs reduces error more per added parameter than adding the same parameters to the base model.","layperson":"A small checker that catches mistakes can improve results more efficiently than just making the main model slightly bigger.","falsification":"On constrained-output tasks (regex, static analyzable code, schema-constrained text), compare (a) base model + tiny verifier vs. (b) a larger base model with equal extra parameters. If (a) does not achieve a larger error reduction per added parameter, the claim is false.","ibm_cost_plan":"NA.","novelty":"Introduces a parameter-efficiency metric showing systematic advantage of verifier modules over uniform base scaling in small models."}]}
